[Database]
# Database connection settings
DATABASE_URL = postgresql://postgres:1e3Xdfsdf23@90.156.204.42:5432/postgres

[Scrapy]
# Scrapy project path
SCRAPY_PROJECT_PATH = news_parser
# Python executable path
PYTHON_PATH = python

[Scheduler]
# Daily spider execution time (24-hour format)
# Test: 11:20 PM (23:20) - 2 minutes from current time
HOUR = 23
MINUTE = 00

# Timezone for scheduling (optional, defaults to system timezone)
# TIMEZONE = UTC

# Logging level
LOG_LEVEL = INFO

# Batch scheduling settings
# Number of spiders to run concurrently in each batch
BATCH_SIZE = 5
# Interval between batches in hours (for manual cycle mode)
BATCH_INTERVAL_HOURS = 4

[Web]
# Flask web server settings
HOST = 0.0.0.0
PORT = 5001
DEBUG = True

[Spider]
# Spider execution settings
# Maximum concurrent spiders (5 = limit to 5 at a time)
MAX_CONCURRENT = 5
# Spider timeout in seconds
TIMEOUT = 3600
# Retry failed spiders
RETRY_FAILED = True
# Maximum retry attempts
MAX_RETRIES = 3 